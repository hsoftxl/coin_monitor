import asyncio
import pandas as pd
import numpy as np
import json
import os
import sys
import time
from datetime import datetime, timedelta
from loguru import logger
import aiohttp
import hmac
import hashlib
import base64
import urllib.parse

# ç¡®ä¿é¡¹ç›®æ ¹ç›®å½•åœ¨è·¯å¾„ä¸­
sys.path.append(os.getcwd())
# åŒæ—¶ä¹Ÿæ”¯æŒåŒç›®å½•å¯¼å…¥
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# å¯¼å…¥æŒ‡çº¹ç®¡ç†å™¨
from src.research.fingerprint_manager import FingerprintManager

# å°è¯•åŠ è½½é…ç½®
try:
    # å°è¯•ä½œä¸ºåŒ…å¯¼å…¥
    from src.research.config import (
        DINGTALK_TOKEN, DINGTALK_SECRET,
        PIR_THRESHOLD, VOL_SPIKE_THRESHOLD, PUMP_THRESHOLD, SHADOW_THRESHOLD
    )
except ImportError:
    try:
        # å°è¯•ç›´æ¥å¯¼å…¥ (å¦‚æœåœ¨åŒä¸€ç›®å½•ä¸‹)
        from config import (
            DINGTALK_TOKEN, DINGTALK_SECRET,
            PIR_THRESHOLD, VOL_SPIKE_THRESHOLD, PUMP_THRESHOLD, SHADOW_THRESHOLD
        )
    except ImportError:
        logger.warning("Config not found, using defaults.")
        DINGTALK_TOKEN = ""
        DINGTALK_SECRET = ""
        PIR_THRESHOLD = 1.2
        VOL_SPIKE_THRESHOLD = 6.0
        PUMP_THRESHOLD = 1.2
        SHADOW_THRESHOLD = 1.2

class BinanceMMTracer:
    def __init__(self):
        self.base_url = "wss://fstream.binance.com/ws"
        self.symbols_data = {} # {symbol: {'klines': deque, 'sum_vol': float}}
        self.max_klines = 30   # ä¿æŒæœ€è¿‘ 30 åˆ†é’Ÿæ•°æ®ç”¨äºè®¡ç®—å‡å€¼
        self.alert_log = "logs/mm_binance_alerts.log"
        os.makedirs("logs", exist_ok=True)
        self.kline_processed_count = 0  
        self.raw_packet_count = 0      # æ–°å¢ï¼šæ¥æ”¶åˆ°çš„åŸå§‹æ•°æ®åŒ…ç»Ÿè®¡
        self.has_received_first = False# æ–°å¢ï¼šæ˜¯å¦æ”¶åˆ°è¿‡æ•°æ®çš„æ ‡å¿—
        self.preload_done = False      # æ–°å¢ï¼šé¢„åŠ è½½æ˜¯å¦å®Œæˆçš„æ ‡å¿—
        self.start_time = time.time()
        self.session = None            # å…±äº« session
        self.semaphore = asyncio.Semaphore(20) # é™åˆ¶å¹¶å‘ API è¯·æ±‚æ•°
        
        # åˆå§‹åŒ–æŒ‡çº¹ç®¡ç†å™¨
        self.fingerprint_manager = FingerprintManager()
        
        # é…ç½®æ—¥å¿—
        logger.remove()
        logger.add(sys.stderr, level="INFO")
        logger.add(self.alert_log, rotation="10 MB", level="SUCCESS", format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}")

    async def get_active_symbols(self):
        """è·å–æ‰€æœ‰äº¤æ˜“ä¸­çš„ USDT æ°¸ç»­åˆçº¦"""
        async with self.session.get("https://fapi.binance.com/fapi/v1/exchangeInfo") as resp:
            data = await resp.json()
            symbols = [
                s['symbol'] for s in data['symbols'] 
                if s['status'] == 'TRADING' and s['symbol'].endswith('USDT') and s['contractType'] == 'PERPETUAL'
            ]
            return [s.lower() for s in symbols]

    async def send_dingtalk_msg(self, content):
        """å‘é€é’‰é’‰å‘Šè­¦æ¶ˆæ¯"""
        if not DINGTALK_TOKEN:
            return
            
        timestamp = str(round(time.time() * 1000))
        
        # å¤„ç† DINGTALK_TOKEN æ˜¯å®Œæ•´ URL çš„æƒ…å†µ
        if DINGTALK_TOKEN.startswith("http"):
            url = DINGTALK_TOKEN
        else:
            url = f"https://oapi.dingtalk.com/robot/send?access_token={DINGTALK_TOKEN}"
        
        if DINGTALK_SECRET:
            secret_enc = DINGTALK_SECRET.encode('utf-8')
            string_to_sign = '{}\n{}'.format(timestamp, DINGTALK_SECRET)
            string_to_sign_enc = string_to_sign.encode('utf-8')
            hmac_code = hmac.new(secret_enc, string_to_sign_enc, digestmod=hashlib.sha256).digest()
            sign = urllib.parse.quote_plus(base64.b64encode(hmac_code))
            connector = "&" if "?" in url else "?"
            url += f"{connector}timestamp={timestamp}&sign={sign}"

        headers = {'Content-Type': 'application/json'}
        data = {
            "msgtype": "text",
            "text": {
                "content": f"ã€å¸å®‰ä¸»åŠ›ç›‘æ§ã€‘\n{content}"
            }
        }
        
        try:
            async with self.session.post(url, json=data, headers=headers) as resp:
                res = await resp.text()
                logger.debug(f"DingTalk response: {res}")
        except Exception as e:
            logger.error(f"Failed to send DingTalk message: {e}")

    async def fetch_history(self, symbol):
        """ä¸ºå•ä¸ªå¸ç§æŠ“å– 30 æ ¹å†å² K çº¿"""
        url = "https://fapi.binance.com/fapi/v1/klines"
        params = {
            "symbol": symbol.upper(),
            "interval": "1m",
            "limit": self.max_klines
        }
        async with self.semaphore:
            try:
                # ç¨å¾®å¢åŠ ä¸€ç‚¹éšæœºå»¶è¿Ÿï¼Œé¿å…ç¬é—´çªå‘æ‰€æœ‰è¯·æ±‚
                await asyncio.sleep(np.random.uniform(0.1, 0.5))
                async with self.session.get(url, params=params) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        history = []
                        for k in data:
                            history.append({'v': float(k[5]), 'c': float(k[4])})
                        return symbol, history
                    elif resp.status == 429:
                        logger.warning(f"Rate limited (429) for {symbol}. Will retry later...")
                        return symbol, []
                    else:
                        logger.warning(f"Failed to fetch history for {symbol}: {resp.status}")
                        return symbol, []
            except Exception as e:
                logger.error(f"Error fetching history for {symbol}: {e}")
                return symbol, []

    async def preload_all_history(self, symbols):
        """å¹¶å‘é¢„åŠ è½½æ‰€æœ‰å¸ç§çš„å†å²æ•°æ®"""
        logger.info(f"ğŸš€ Starting history backfill for {len(symbols)} symbols...")
        tasks = [self.fetch_history(s) for s in symbols]
        results = await asyncio.gather(*tasks)
        
        count = 0
        for symbol, history in results:
            if history:
                self.symbols_data[symbol] = history
                count += 1
        
        self.preload_done = True
        logger.success(f"âœ… History backfill complete. Loaded history for {count}/{len(symbols)} symbols.")

    def process_kline(self, symbol, k):
        """å¤„ç†å•æ¡ K çº¿å¹¶æ£€æµ‹æŒ‡çº¹"""
        # æ•°æ®ç»“æ„: [t, o, h, l, c, v, T, q, n, V, Q, B]
        # æˆ‘ä»¬éœ€è¦: c, v, h, o, q (quote volume)
        try:
            self.raw_packet_count += 1
            if not self.has_received_first:
                self.has_received_first = True
                logger.info(f"âœ… æ•°æ®æµå·²æ¿€æ´»! ä» {symbol.upper()} æ”¶åˆ°ç¬¬ä¸€ä¸ªæ•°æ®åŒ…")

            close = float(k['c'])
            high = float(k['h'])
            low = float(k['l'])
            open_p = float(k['o'])
            vol = float(k['v'])
            quote_vol = float(k['q'])
            is_closed = k['x'] # æ˜¯å¦æ˜¯é—­åˆ K çº¿
            
            if not is_closed:
                return # ä»…å¤„ç†é—­åˆåˆ†é’Ÿ K çº¿ä»¥ä¿è¯å‡†ç¡®æ€§

            if symbol not in self.symbols_data:
                self.symbols_data[symbol] = []
            
            history = self.symbols_data[symbol]
            history.append({'v': vol, 'c': close})
            if len(history) > self.max_klines:
                history.pop(0)

            if len(history) < 20: 
                # æ¯ç§¯ç´¯ 5 åˆ†é’Ÿæ‰“å°ä¸€æ¬¡è¿›åº¦ï¼Œå‡å°‘æ—¥å¿—é‡
                if len(history) % 5 == 0:
                    logger.debug(f"{symbol.upper()}: Baseline data accumulating ({len(history)}/20)...")
                return # å†å²æ•°æ®ä¸è¶³ï¼Œä¸è¿›è¡Œé¢„è­¦åˆ†æ

            self.kline_processed_count += 1

            # --- æŒ‡çº¹è®¡ç®—é€»è¾‘ ---
            # 1. æˆäº¤é‡å‡å€¼
            avg_vol = sum(h['v'] for h in history[:-1]) / (len(history) - 1)
            vol_spike = vol / avg_vol if avg_vol > 0 else 0
            
            # 2. ä»·æ ¼å˜åŒ–
            price_pct = (close - open_p) / open_p * 100
            
            # 3. PIR (ä»·æ ¼å†²å‡»æ¯”) -> æ¶¨å¹… / (æˆäº¤é¢ (ç™¾ä¸‡USDT))
            # é¢„ä¼°å‡€æµ: å¦‚æœæ¶¨ï¼Œè§†ä¸ºæ­£æµ
            est_flow_m = quote_vol / 1e6
            pir = price_pct / est_flow_m if est_flow_m > 0.01 else 0 # è¿‡æ»¤æå°é¢
            
            # 4. å½±çº¿åˆ†æ
            upper_shadow = (high - max(open_p, close)) / close * 100
            lower_shadow = (min(open_p, close) - low) / close * 100
            
            # 5. æ­£èµ„é‡‘æµå…¥å æ¯” (åŸºäºæœ€è¿‘5åˆ†é’Ÿ)
            recent_history = history[-5:] if len(history) >=5 else history
            positive_flows = sum(1 for h in recent_history if h['c'] > h.get('open', h['c'])) / len(recent_history)
            
            # 6. å¤§å•å æ¯”æ¨¡æ‹Ÿ (åŸºäºæˆäº¤é¢å¤§å°)
            is_big_order = quote_vol > 5000  # æˆäº¤é¢ > 5000 USDT è§†ä¸ºå¤§å•
            big_order_ratio = 1.0 if is_big_order else 0.0
            
            # 7. ç»¼åˆåˆ¤å®šé¢„è­¦ ---
            # åŸºç¡€å‘Šè­¦æ¡ä»¶ (åŸæœ‰é€»è¾‘)
            is_ignition = (vol_spike > VOL_SPIKE_THRESHOLD) and (price_pct > PUMP_THRESHOLD)
            is_high_pir = (pir > PIR_THRESHOLD) and (price_pct > 0.5)
            
            # å®æ—¶æŒ‡æ ‡ï¼Œç”¨äºæŒ‡çº¹åŒ¹é…
            real_time_metrics = {
                "pir": pir,
                "vol_spike": vol_spike,
                "price_pct": price_pct,
                "positive_flow_ratio": positive_flows,
                "big_order_ratio": big_order_ratio,
                "upper_shadow": upper_shadow,
                "lower_shadow": lower_shadow
            }
            
            # æ£€æŸ¥æ˜¯å¦ç¬¦åˆæŒ‡çº¹ç‰¹å¾ (ä¸»åŠ›æ‹‰ç›˜èµ·çˆ†ç‚¹)
            is_fingerprint_match, match_score = self.fingerprint_manager.is_valid_fingerprint(symbol, real_time_metrics)
            
            if is_fingerprint_match:
                # ä¸»åŠ›æ‹‰ç›˜èµ·çˆ†ç‚¹å‘Šè­¦ - ä¸­æ–‡æ–‡æ¡ˆ
                msg = (f"ğŸš€ [ğŸ”¥ ä¸»åŠ›æ‹‰ç›˜èµ·çˆ†ç‚¹] {symbol.upper()} | åŒ¹é…å¾—åˆ†: {match_score}/100 | "
                       f"ä»·æ ¼: {price_pct:+.2f}% | PIR: {pir:.2f} | "
                       f"æˆäº¤é‡å³°å€¼: {vol_spike:.1f}x | æ­£èµ„é‡‘æµå…¥: {positive_flows:.1%} | "
                       f"å¤§å•: {'æ˜¯' if is_big_order else 'å¦'} | ä¸Šå½±çº¿: {upper_shadow:.2f}%")
                
                logger.success(msg)
                # å¼‚æ­¥æ¨é€é’‰é’‰ï¼Œä½¿ç”¨æ›´é†’ç›®çš„å‘Šè­¦æ ¼å¼
                asyncio.create_task(self.send_dingtalk_msg(f"ğŸ”¥ğŸ”¥ğŸ”¥ {msg}"))
                print(f"\a\a\a") # è¿ç»­èœ‚é¸£æç¤º
            elif is_ignition or is_high_pir:
                # æ™®é€š MM å‘Šè­¦ - ä¸­æ–‡æ–‡æ¡ˆ
                score = 0
                if is_ignition: score += 50
                if is_high_pir: score += 30
                if upper_shadow > SHADOW_THRESHOLD: score += 20
                
                # åªæœ‰å¾—åˆ†è¶…è¿‡40åˆ†æ—¶æ‰å‘é€é€šçŸ¥
                if score > 40:
                    msg = (f"âš ï¸  [ä¸»åŠ›ç›‘æ§å‘Šè­¦] {symbol.upper()} | å¾—åˆ†: {score} | "
                           f"ä»·æ ¼: {price_pct:+.2f}% | PIR: {pir:.2f} | "
                           f"æˆäº¤é‡å³°å€¼: {vol_spike:.1f}x | ä¸Šå½±çº¿: {upper_shadow:.2f}%")
                    
                    logger.success(msg)
                    # å¼‚æ­¥æ¨é€é’‰é’‰
                    asyncio.create_task(self.send_dingtalk_msg(msg))
                    print(f"\a") # ç»ˆç«¯èœ‚é¸£æç¤º (å¦‚æœæ”¯æŒ)

        except Exception as e:
            logger.error(f"Error processing {symbol}: {e}")

    async def heartbeat(self):
        """æŠ¥å‘ŠçŠ¶æ€ã€‚å‰2åˆ†é’Ÿæ¯10ç§’æŠ¥ä¸€æ¬¡ï¼Œä¹‹åæ¯åˆ†é’Ÿä¸€æ¬¡"""
        count = 0
        while True:
            interval = 10 if count < 12 else 60 
            await asyncio.sleep(interval)
            count += 1
            
            uptime = str(timedelta(seconds=int(time.time() - self.start_time)))
            if not self.preload_done:
                status = "ğŸ“¥ æ­£åœ¨é¢„åŠ è½½å†å²æ•°æ®..."
            else:
                status = "ğŸ”¥ æ­£åœ¨ç›‘æ§" if self.kline_processed_count > 0 else "â³ ç­‰å¾…æ–°Kçº¿..."
            
            logger.info(f"ğŸ’“ {status} | è¿è¡Œæ—¶é—´: {uptime} | å¤„ç†Kçº¿æ•°: {self.kline_processed_count} | åŸå§‹æ•°æ®åŒ…: {self.raw_packet_count}")

    async def run_forever(self):
        """æŒç»­è¿è¡Œçš„ WebSocket ç›‘å¬ä¸»å¾ªç¯"""
        self.session = aiohttp.ClientSession()
        asyncio.create_task(self.heartbeat()) 
        while True:
            try:
                symbols = await self.get_active_symbols()
                
                # åˆå§‹é¢„åŠ è½½
                if not self.preload_done:
                    await self.preload_all_history(symbols)
                
                logger.info(f"âœ… è¿æ¥æˆåŠŸ. æ­£åœ¨ç›‘æ§ {len(symbols)} ä¸ªå¸å®‰æ°¸ç»­åˆçº¦...")
                
                # å¸å®‰ WebSocket é™åˆ¶ï¼šå•ä¸ªè¿æ¥æœ€å¤š 200 ä¸ª streams
                # æˆ‘ä»¬åˆ†æ‰¹è®¢é˜…
                batch_size = 150
                tasks = []
                for i in range(0, len(symbols), batch_size):
                    batch = symbols[i : i + batch_size]
                    tasks.append(self.listen_batch(batch))
                
                await asyncio.gather(*tasks)
                
            except Exception as e:
                logger.error(f"âŒ ä¸»å¾ªç¯å´©æºƒ: {e}. 10ç§’åé‡è¯•...")
                await asyncio.sleep(10)

    async def listen_batch(self, batch):
        """ç›‘å¬ä¸€æ‰¹å¸ç§çš„æ•°æ®æµ"""
        streams = "/".join([f"{s}@kline_1m" for s in batch])
        url = f"{self.base_url}/{streams}"
        
        async with self.session.ws_connect(url) as ws:
            logger.info(f"ğŸ“¡ Subscribed to batch of {len(batch)} symbols. Waiting for data...")
            async for msg in ws:
                if msg.type == aiohttp.WSMsgType.TEXT:
                    data = json.loads(msg.data)
                    if 'data' in data: # å¤åˆæµæ ¼å¼
                        symbol = data['data']['s'].lower()
                        kline = data['data']['k']
                        self.process_kline(symbol, kline)
                    else: # å•ä¸€æµæ ¼å¼ (è™½ç„¶æˆ‘ä»¬ç”¨çš„æ˜¯å¤åˆ)
                        symbol = data['s'].lower()
                        kline = data['k']
                        self.process_kline(symbol, kline)
                elif msg.type in (aiohttp.WSMsgType.CLOSED, aiohttp.WSMsgType.ERROR):
                    break
        logger.warning("Batch connection closed. Reconnecting...")

if __name__ == "__main__":
    tracer = BinanceMMTracer()
    try:
        asyncio.run(tracer.run_forever())
    except KeyboardInterrupt:
        logger.info("Stopped by user.")
