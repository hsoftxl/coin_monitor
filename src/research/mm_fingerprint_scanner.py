import asyncio
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import os
import sys
from loguru import logger
import ccxt.async_support as ccxt

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.getcwd())

# å¯¼å…¥æŒ‡çº¹ç®¡ç†å™¨
from src.research.fingerprint_manager import FingerprintManager

class MMFingerprintScanner:
    def __init__(self):
        # å°†è¾“å‡ºç›®å½•æ”¹ä¸ºåŒçº§çš„ data ç›®å½•
        self.output_dir = os.path.join(os.path.dirname(__file__), "data")
        os.makedirs(self.output_dir, exist_ok=True)
        self.exchange = ccxt.binance({
            'enableRateLimit': True,
            'options': {
                'defaultType': 'future'
            }
        })
        self.results = []
        
        # åˆå§‹åŒ–æŒ‡çº¹ç®¡ç†å™¨
        self.fingerprint_manager = FingerprintManager()
        
        # ç›®æ ‡æŒ‡çº¹ç‰¹å¾ (åŸºäº LIGHT åˆ†æç»“æœ)
        self.TARGET_PIR_MIN = 1.2
        self.TARGET_IGNITION_HOURS = [8, 9] # UTC 8-9 æ—¶
        self.TARGET_ACCUMULATION_RATIO = 0.15 # 15% ä»¥ä¸Šä½æ³¢æœŸ
        
        # æ–°å¢ï¼šæŒ‡æ ‡ç»†åˆ†å‚æ•°
        self.BIG_ORDER_THRESHOLD = 5000  # å¤§å•é˜ˆå€¼ (USDT)
        self.TAKER_BUY_RATIO_THRESHOLD = 0.6  # ä¸»åŠ¨ä¹°å…¥å æ¯”é˜ˆå€¼
        self.VOLUME_SPIKE_THRESHOLD = 6.0  # æˆäº¤é‡å³°å€¼é˜ˆå€¼
        self.PRICE_PUMP_THRESHOLD = 1.2  # ä»·æ ¼æ¶¨å¹…é˜ˆå€¼
        self.SHADOW_RATIO_THRESHOLD = 1.2  # ä¸Šå½±çº¿æ¯”ä¾‹é˜ˆå€¼
        
    async def get_all_symbols(self, only_light=False):
        markets = await self.exchange.load_markets()
        
        # å¦‚æœ only_light ä¸º Trueï¼Œåªè¿”å› LIGHT å¸
        if only_light:
            light_symbol = next((s for s, m in markets.items() 
                              if (m.get('type') == 'swap' or 'swap' in m.get('info', {}).get('contractType', '').lower()) 
                              and ('LIGHT' in s) 
                              and (s.endswith('/USDT') or s.endswith('USDT'))), None)
            symbols = [light_symbol] if light_symbol else []
            logger.info(f"Using only LIGHT symbol: {symbols}")
            return symbols
        
        # å¦åˆ™è¿”å›æ‰€æœ‰ USDT æ°¸ç»­åˆçº¦
        symbols = []
        for s, m in markets.items():
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ°¸ç»­åˆçº¦
            is_swap = m.get('type') == 'swap' or 'swap' in m.get('info', {}).get('contractType', '').lower()
            # æ£€æŸ¥æ˜¯å¦æ˜¯ USDT è®¡ä»·
            is_usdt = s.endswith('/USDT') or s.endswith('USDT')
            if is_swap and is_usdt:
                symbols.append(s)
        
        logger.info(f"Found {len(symbols)} USDT-SWAP symbols on Binance")
        return symbols

    async def analyze_symbol(self, symbol, use_specific_periods=True):
        """
        åˆ†æå•ä¸ªå¸ç§çš„æŒ‡çº¹ç‰¹å¾
        
        Args:
            symbol: å¸ç§ç¬¦å·
            use_specific_periods: æ˜¯å¦ä½¿ç”¨æŒ‡å®šçš„ä¸»åŠ›åšå¸‚æ—¶é—´æ®µï¼ˆ2025-12-18 è‡³ 2025-12-22 å’Œ 2025-12-30 è‡³ 2026-01-02ï¼‰
        """
        try:
            if use_specific_periods:
                # ä¸»åŠ›åšå¸‚æ—¶é—´æ®µ
                periods = [
                    # æ—¶æ®µ 1: 2025-12-18 00:00 è‡³ 2025-12-22 23:59
                    {
                        'start': datetime(2025, 12, 18, 0, 0),
                        'end': datetime(2025, 12, 22, 23, 59)
                    },
                    # æ—¶æ®µ 2: 2025-12-30 00:00 è‡³ 2026-01-02 23:59
                    {
                        'start': datetime(2025, 12, 30, 0, 0),
                        'end': datetime(2026, 1, 2, 23, 59)
                    }
                ]
                
                all_ohlcv = []
                for period in periods:
                    # å°† datetime è½¬æ¢ä¸º timestampï¼ˆæ¯«ç§’ï¼‰
                    start_ts = int(period['start'].timestamp() * 1000)
                    end_ts = int(period['end'].timestamp() * 1000)
                    
                    # è®¡ç®—éœ€è¦è·å–çš„ K çº¿æ•°é‡ï¼ˆæ¯åˆ†é’Ÿä¸€æ ¹ï¼‰
                    minutes = int((end_ts - start_ts) / (1000 * 60)) + 1
                    
                    logger.info(f"ğŸ“Š Fetching {minutes} candles for {symbol} from {period['start']} to {period['end']}")
                    ohlcv = await self.exchange.fetch_ohlcv(symbol, '1m', since=start_ts, limit=minutes)
                    if ohlcv:
                        all_ohlcv.extend(ohlcv)
                        logger.info(f"âœ… Fetched {len(ohlcv)} candles for period {period['start']} to {period['end']}")
                
                ohlcv = all_ohlcv
            else:
                # é»˜è®¤ä½¿ç”¨æœ€è¿‘3å¤©çš„æ•°æ®
                days = 3
                start_time = int((datetime.now() - timedelta(days=days)).timestamp() * 1000)
                ohlcv = await self.exchange.fetch_ohlcv(symbol, '1m', since=start_time, limit=1440 * days)
            
            if not ohlcv:
                logger.debug(f"{symbol}: No OHLCV data fetched.")
                return None
                
            if len(ohlcv) < 100: # æ”¾å®½é™åˆ¶ç”¨äºè°ƒè¯•
                logger.debug(f"{symbol}: Data length too short ({len(ohlcv)})")
                return None
                
            df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
            
            # åŸºç¡€æŒ‡æ ‡è®¡ç®—
            df['price_pct'] = df['close'].pct_change() * 100
            df['amount'] = df['close'] * df['volume']
            df['vol_ma'] = df['volume'].rolling(window=20).mean()
            df['vol_spike'] = df['volume'] / df['vol_ma']
            df['vol_ma_60'] = df['volume'].rolling(window=60).mean()
            df['vol_spike_60'] = df['volume'] / df['vol_ma_60']
            
            # æ–°å¢æŒ‡æ ‡ 1: èµ„é‡‘æµå‘åˆ†æ
            # é¢„ä¼°å‡€æµ: æ”¶ç›˜ > å¼€ç›˜ è®¾ä¸ºæµå…¥
            df['est_flow'] = np.where(df['close'] > df['open'], df['amount'], -df['amount'])
            df['cum_est_flow'] = df['est_flow'].cumsum()
            df['flow_ratio'] = df['est_flow'].abs() / df['amount']
            
            # æ–°å¢æŒ‡æ ‡ 2: ä¹°å–ç›˜ç‰¹å¾
            # ä¸»åŠ¨ä¹°å…¥å æ¯” (åŸºäº K çº¿æ¶¨è·Œ)
            df['taker_buy_ratio'] = np.where(df['close'] > df['open'], 
                                            df['volume'] / df['volume'], 
                                            0)
            df['avg_taker_buy_ratio'] = df['taker_buy_ratio'].rolling(window=10).mean()
            
            # æ–°å¢æŒ‡æ ‡ 3: å¤§å•å æ¯”æ¨¡æ‹Ÿ
            # åŸºäºæˆäº¤é¢å¤§å°åˆ’åˆ†å¤§å•
            df['is_big_order'] = df['amount'] > self.BIG_ORDER_THRESHOLD
            
            # æ–°å¢æŒ‡æ ‡ 4: ä»·æ ¼æ³¢åŠ¨ç‰¹å¾
            # è¿ç»­ä¸Šæ¶¨/ä¸‹è·Œå¤©æ•°
            df['is_up'] = df['price_pct'] > 0
            df['up_streak'] = df['is_up'].groupby((~df['is_up']).cumsum()).cumsum()
            df['down_streak'] = (~df['is_up']).groupby(df['is_up'].cumsum()).cumsum()
            
            # æ–°å¢æŒ‡æ ‡ 5: æ³¢åŠ¨ç‡ç‰¹å¾
            df['volatility'] = df['price_pct'].rolling(window=20).std()
            df['volatility_ratio'] = df['volatility'] / df['volatility'].rolling(window=60).mean()
            
            # æ–°å¢æŒ‡æ ‡ 6: ä»·æ ¼ä¸æˆäº¤é‡ç›¸å…³æ€§
            df['price_vol_corr'] = df['price_pct'].rolling(window=30).corr(df['volume'])
            
            # 1. PIR è®¡ç®— (æ‹‰å‡æ•ˆç‡)
            # é¢„ä¼°å‡€æµ: æ”¶ç›˜ > å¼€ç›˜ è®¾ä¸ºæµå…¥
            df['est_flow'] = np.where(df['close'] > df['open'], df['amount'], -df['amount'])
            up_minutes = df[(df['price_pct'] > 0.5) & (df['amount'] > 10000)].copy()
            if len(up_minutes) < 5:
                return None
                
            pir_median = (up_minutes['price_pct'] / (up_minutes['est_flow'] / 1e6)).median()
            
            # 2. ç‚¹ç«æ¬¡æ•°ç»Ÿè®¡ï¼ˆç§»é™¤æ—¶é—´çª—å£åˆ†æï¼‰
            ignitions = df[(df['vol_spike'] > self.VOLUME_SPIKE_THRESHOLD) & (df['price_pct'] > self.PRICE_PUMP_THRESHOLD)]
            total_ignitions = len(ignitions)
            # ç§»é™¤æ—¶é—´çª—å£åŒ¹é…ç›¸å…³é€»è¾‘
            window_score = 0
                
            # 3. å½±çº¿åˆ†æ
            df['upper_shadow'] = (df['high'] - df[['open', 'close']].max(axis=1)) / df['close'] * 100
            df['lower_shadow'] = (df[['open', 'close']].min(axis=1) - df['low']) / df['close'] * 100
            heavy_shadow_count = len(df[df['upper_shadow'] > self.SHADOW_RATIO_THRESHOLD])
            avg_upper_shadow = df['upper_shadow'].mean()
            avg_lower_shadow = df['lower_shadow'].mean()
            
            # 4. æ³¢åŠ¨ç‡å¹³ç¨³æœŸå æ¯”
            rolling_std = df['close'].rolling(window=60).std() / df['close'].rolling(window=60).mean() * 100
            low_vol_ratio = len(rolling_std[rolling_std < rolling_std.quantile(0.2)]) / len(df)
            
            # 5. æ–°å¢ï¼šèµ„é‡‘æµå‘ç‰¹å¾
            # æ­£èµ„é‡‘æµå…¥å æ¯”
            positive_flow_ratio = len(df[df['est_flow'] > 0]) / len(df)
            avg_flow = df['est_flow'].mean()
            
            # 6. æ–°å¢ï¼šå¤§å•ç‰¹å¾
            big_order_volume = df[df['is_big_order']]['volume'].sum()
            total_volume = df['volume'].sum()
            big_order_ratio = big_order_volume / total_volume if total_volume > 0 else 0
            
            # 7. æ–°å¢ï¼šè¿ç»­ä¸Šæ¶¨åŠ¨èƒ½
            strong_up_moves = len(df[(df['price_pct'] > 2.0) & (df['vol_spike'] > 4.0)])
            max_up_streak = df['up_streak'].max()
            
            # 8. æ–°å¢ï¼šæˆäº¤é‡é›†ä¸­åº¦
            # æˆäº¤é‡å‰ 10% å æ€»æˆäº¤é‡æ¯”ä¾‹
            top_10_vol = df['volume'].nlargest(int(len(df) * 0.1)).sum()
            volume_concentration = top_10_vol / total_volume if total_volume > 0 else 0
            
            # 9. æ–°å¢ï¼šå¹³å‡æ³¢åŠ¨ç‰¹å¾
            avg_price_pct = df['price_pct'].mean()
            max_1m_pump = df['price_pct'].max()
            
            # 10. æ–°å¢ï¼šä»·æ ¼ä¸æˆäº¤é‡ç›¸å…³æ€§
            avg_price_vol_corr = df['price_vol_corr'].mean() if 'price_vol_corr' in df.columns else 0
            
            # ä¼˜åŒ–è¯„åˆ†æœºåˆ¶ (æ»¡åˆ† 100)
            # ç§»é™¤æ—¶é—´çª—å£åŒ¹é…ï¼Œè°ƒæ•´æƒé‡åˆ†é…
            # æ–°æƒé‡ï¼šPIR (30%)ã€èµ„é‡‘æµå‘ (20%)ã€æˆäº¤é‡ç‰¹å¾ (20%)ã€ä»·æ ¼ç‰¹å¾ (20%)ã€å½¢æ€ç‰¹å¾ (10%)
            score = 0
            
            # 1. PIR è¡¨ç° (30åˆ†) - å¢åŠ 5åˆ†
            if pir_median > self.TARGET_PIR_MIN:
                score += 30 * min(pir_median / (self.TARGET_PIR_MIN * 2), 1.0)
            
            # 2. èµ„é‡‘æµå‘ç‰¹å¾ (20åˆ†) - å¢åŠ 5åˆ†
            # æ­£èµ„é‡‘æµå…¥å æ¯”
            if positive_flow_ratio > 0.5:
                score += 20 * min(positive_flow_ratio, 1.0)
            
            # 3. æˆäº¤é‡ç‰¹å¾ (20åˆ†) - å¢åŠ 5åˆ†
            # æˆäº¤é‡å³°å€¼æƒ…å†µ
            high_vol_spikes = len(df[(df['vol_spike'] > 4.0) & (df['price_pct'] > 0.5)])
            score += min(high_vol_spikes * 0.7, 15)  # å¢åŠ å³°å€¼æƒé‡
            # å¤§å•å æ¯”
            if big_order_ratio > 0.3:
                score += 5
            
            # 4. ä»·æ ¼æ³¢åŠ¨ç‰¹å¾ (20åˆ†) - å¢åŠ 5åˆ†
            # è¿ç»­ä¸Šæ¶¨åŠ¨èƒ½
            score += min(strong_up_moves * 2.5, 15)  # å¢åŠ ä¸Šæ¶¨åŠ¨èƒ½æƒé‡
            # æ³¢åŠ¨ç‡å¹³ç¨³æœŸ
            if low_vol_ratio > self.TARGET_ACCUMULATION_RATIO:
                score += 5
            
            # 5. å½¢æ€ç‰¹å¾ (10åˆ†) - ä¿æŒä¸å˜
            # å½±çº¿ç‰¹å¾
            if avg_upper_shadow < 0.5:  # ä¸Šå½±çº¿çŸ­ï¼Œå¤šå¤´å¼ºåŠ¿
                score += 5
            if avg_lower_shadow > 1.0:  # ä¸‹å½±çº¿é•¿ï¼Œæ”¯æ’‘å¼ºåŠ²
                score += 5
            
            # æœ€ç»ˆè¯„åˆ†é™åˆ¶åœ¨ 0-100 ä¹‹é—´
            score = max(0, min(100, score))
            
            return {
                'symbol': symbol,
                'score': score,
                # åŸºç¡€æŒ‡æ ‡
                'pir_median': pir_median,
                'window_hit_rate': window_score,
                'low_vol_ratio': low_vol_ratio,
                'heavy_shadow_count': heavy_shadow_count,
                'total_ignitions': total_ignitions,
                'max_1m_pump': max_1m_pump,
                # æ–°å¢æŒ‡æ ‡ï¼šèµ„é‡‘æµå‘
                'positive_flow_ratio': positive_flow_ratio,
                'avg_flow': avg_flow,
                # æ–°å¢æŒ‡æ ‡ï¼šä¹°å–ç›˜ç‰¹å¾
                'avg_taker_buy_ratio': df['avg_taker_buy_ratio'].mean(),
                # æ–°å¢æŒ‡æ ‡ï¼šå¤§å•ç‰¹å¾
                'big_order_ratio': big_order_ratio,
                # æ–°å¢æŒ‡æ ‡ï¼šä»·æ ¼æ³¢åŠ¨
                'strong_up_moves': strong_up_moves,
                'max_up_streak': max_up_streak,
                'avg_price_pct': avg_price_pct,
                # æ–°å¢æŒ‡æ ‡ï¼šæˆäº¤é‡ç‰¹å¾
                'volume_concentration': volume_concentration,
                # æ–°å¢æŒ‡æ ‡ï¼šå½¢æ€ç‰¹å¾
                'avg_upper_shadow': avg_upper_shadow,
                'avg_lower_shadow': avg_lower_shadow,
                # æ–°å¢æŒ‡æ ‡ï¼šç›¸å…³æ€§
                'avg_price_vol_corr': avg_price_vol_corr,
                'volatility_ratio': df['volatility_ratio'].mean()
            }
            
        except Exception as e:
            logger.debug(f"{symbol}: Exception during analysis: {e}")
            return {'symbol': symbol, 'score': 0, 'error': str(e)}

    async def run_scan(self, only_light=True):
        """
        è¿è¡ŒæŒ‡çº¹æ‰«æ
        
        Args:
            only_light: æ˜¯å¦åªæ‰«æ LIGHT å¸
        """
        # é»˜è®¤åªæ‰«æ LIGHT å¸ï¼Œä½¿ç”¨ç‰¹å®šæ—¶é—´æ®µ
        symbols = await self.get_all_symbols(only_light=only_light)
        logger.info(f"Starting parallel scanning for {len(symbols)} symbols...")
        
        # é™ä½å¹¶å‘ï¼Œå¯¹äºå•ä¸ªå¸ç§å¯ä»¥è®¾ç½®ä¸º 1
        sem = asyncio.Semaphore(1 if only_light else 5) 
        
        async def sem_analyze(symbol):
            async with sem:
                # å¯¹äº LIGHT å¸ï¼Œå¼ºåˆ¶ä½¿ç”¨ç‰¹å®šæ—¶é—´æ®µ
                res = await self.analyze_symbol(symbol, use_specific_periods=True)
                if res and res.get('score', 0) >= 1:
                    print(f"   [PROCESSED] {symbol} | Score: {res['score']:.1f}", end='\r')
                return res

        tasks = [sem_analyze(s) for s in symbols]
        all_results = await asyncio.gather(*tasks)
        
        self.results = [r for r in all_results if r is not None]
        
        if not self.results:
            logger.warning("No symbols analyzed successfully.")
            await self.exchange.close()
            return

        # è¿‡æ»¤æ‰æŠ¥é”™çš„è®°å½•
        valid_results = [r for r in self.results if 'score' in r]
        valid_results.sort(key=lambda x: x['score'], reverse=True)
        
        # å¯¼å‡ºç»“æœ
        df_res = pd.DataFrame(valid_results)
        df_res.to_csv(f"{self.output_dir}/scan_results.csv", index=False)
        logger.info(f"Scan complete. Total: {len(valid_results)}. Top results saved.")
        
        print(f"\n\n--- LIGHT å¸ç§åœ¨ç»“æœä¸­çš„ä½ç½® ---")
        light_entry = df_res[df_res['symbol'] == 'LIGHT/USDT']
        print(light_entry if not light_entry.empty else "Not Found in results!")

        print("\n\n--- æ‰«æç»“æœ Top 20 (ä¸»åŠ›ç‰¹å¾è¯„åˆ†æ’å) ---")
        # è¾“å‡ºæ›´å¤šå…³é”®æŒ‡æ ‡
        cols_to_print = [c for c in ['symbol', 'score', 'pir_median', 'window_hit_rate', 'total_ignitions', 
                                     'positive_flow_ratio', 'big_order_ratio', 'strong_up_moves', 
                                     'volume_concentration', 'max_1m_pump'] if c in df_res.columns]
        print(df_res.head(20)[cols_to_print])
        
        # ä¿å­˜æ‰«æç»“æœä¸ºæŒ‡çº¹
        print(f"\n\n--- ä¿å­˜æŒ‡çº¹æ•°æ® ---")
        saved_count = 0
        for _, row in df_res.iterrows():
            # åªä¿å­˜è¯„åˆ†è¾ƒé«˜çš„æŒ‡çº¹
            if row['score'] >= 50:
                # æå–å…³é”®æŒ‡æ ‡
                metrics = {
                    'pir_median': row.get('pir_median', 0),
                    'window_hit_rate': row.get('window_hit_rate', 0),
                    'positive_flow_ratio': row.get('positive_flow_ratio', 0),
                    'big_order_ratio': row.get('big_order_ratio', 0),
                    'strong_up_moves': row.get('strong_up_moves', 0),
                    'volume_concentration': row.get('volume_concentration', 0),
                    'avg_upper_shadow': row.get('avg_upper_shadow', 0),
                    'avg_lower_shadow': row.get('avg_lower_shadow', 0),
                    'volatility_ratio': row.get('volatility_ratio', 0)
                }
                # ä¿å­˜æŒ‡çº¹
                self.fingerprint_manager.add_fingerprint(row['symbol'], metrics, row['score'])
                saved_count += 1
        print(f"âœ… æˆåŠŸä¿å­˜ {saved_count} ä¸ªæŒ‡çº¹")
        
        # è¾“å‡ºæŒ‡çº¹ç»Ÿè®¡ä¿¡æ¯
        stats = self.fingerprint_manager.get_fingerprint_stats()
        print(f"ğŸ“Š æŒ‡çº¹ç»Ÿè®¡: æ€»è®¡ {stats['total']} ä¸ª, æ´»è·ƒ {stats['active']} ä¸ª, å¹³å‡è¯„åˆ† {stats['avg_score']}")
        
        await self.exchange.close()

if __name__ == "__main__":
    scanner = MMFingerprintScanner()
    asyncio.run(scanner.run_scan())
